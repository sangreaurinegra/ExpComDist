
\textbf{\emph{An Experimental Study on Microservices based Edge Computing Platforms}} 
\cite{qu_experimental_2020}.

Motivado por la arquitectura de microservicios y su aplicación en ciudades inteligentes
este articulo investigó múltiples políticas de despliegue en plataformas de computación de borde (edge).
Argumentando contra las VM´s haciendo referencia a estudios de IBM en cuanto al consumo de recursos \cite{IBM_DockerVsVm_s} comparando ejecuciones con Spark % \cite{} 
y big data, y basándose además del estudio en el área big data sobre la interferencia causada entre contenedores vecinos ejecutando microservicios sobre big data.% \cite{}.
Para la investigación se utilizaron contenedores docker y a través de pruebas experimentales en distintos escenarios. Se comparó el desempeño de las mismas, considerando que la capacidad de recolectar y procesar los datos de borde es la clave.
Los investigadores evaluaron si es apropiado ejecutar múltiples microservicios dentro de un contenedor considerando la performance del dispositivo.
En caso de que fuese viable, evaluaron que tipos de microservicios son agrupables en cuanto al perfil de consumo de recursos.
Verificaron si el efecto de interferencia al ejecutar múltiples microservicios en la computación de neblina (fog) es el mismo que en la computación de borde (edge). Compararon la distribución de microservicios tomando en cuenta la regla de un proceso por contenedor (o un contenedor por servicio \cite{cont_por_serv} ) contra las limitaciones de recursos en el borde (edge) en términos de computación y memoria. Para ello evaluaron la perfomrmace de las CPU con Linpack benchmarks %\cite{}
, la performance de la memoria STREAM benchmarks % cite\{} 
y la del disco con Bonnie++ benchmark. Como ambiente se utilizó para computación en la neblina (fog) una maquina de escritorio 4,5GHz Intel Core TM (4 núcleos), 4GB DDR3 RAM y 50G HHD , sobre Ubuntu 16.04 . Y para la computación de borde (edge) Raspberry Pi 4, Quad Core Cortex-A72 (ARM v8) 1,5 Ghz, 4GB LPDDR4 RAM y 32GB microSD card, sobre Raspbian GNU/Linux.Se plantearon cuatro casos a evaluar. El primero, una única instancia de microservicio por contenedor y solo un contenedor ejecutándose en el host. El segundo, múltiples instancias de microservicios en un contenedor y solo contenedor ejecutándose en el host. El tercero cada contenedor albergó una única instancia de microservicio y múltiples contenedores ejecutándose en el host. El cuarto cada contenedor albergó una única instancia de microservicio y múltiples contenedores ejecutaron en el host con la limitante de la utilización de cgroups (NOTA O CITA) para limitar el acceso al sistema durante el test. Con las mencionadas herramientas de benchmarks y y posibles configuraciones en los casos mencionados, se realizaron los test decidiendo según el resultado que flujo de test seguir. DE esa manera se realizó la evaluación de las diferentes distribuciones en la neblina (fog) y en el borde (edge). Llegando a concluir que en ambiente de computación de borde el ejecutar múltiples instancias de microservicios en un contenedor tiene como ventaja una mejora en la performance en la mayoría de los casos pero tiene como gran desventaja que al momento de escalar en contenedores se replican todos los microservicios desplegados en el contenedor y no solo los necesarios por lo que resulta contraproducente en recursos. En cuanto al uso de la memoria no se verificaron diferencias significativas salvo cuando microservicios similares dentro de un contenedor competían por el mismo recurso. Lo mismo para la entrada salida del disco. Para finalizar plantearon realizar un prototipo a mayor escala con los datos relevados.


NOTA
La computación de niebla, también conocida como redes en la niebla o niebla, es una infraestructura de computación descentralizada en la que los datos, el cómputo, el almacenamiento y las aplicaciones están distribuidos en el lugar más lógico y eficiente entre la fuente de datos y la nube.
% cite{webfog}
